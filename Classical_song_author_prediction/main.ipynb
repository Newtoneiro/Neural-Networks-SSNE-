{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q82Zk9-9hzMr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "TK1WNO7NYbVl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wijPtsMCiB-w"
      },
      "source": [
        "# Preparations for GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "RGCWfBJMg_Um"
      },
      "outputs": [],
      "source": [
        "torch.cuda.set_device(0)\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJcjQErmYfky"
      },
      "source": [
        "# Seeding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKaH5X69YepG",
        "outputId": "7b0f1e6d-4848-4b16-df07-b4c49fe720d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7b2bd895d0>"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SEED = 42\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMwbQNu_7S79"
      },
      "source": [
        "# Getting data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "qUOoEeiQYbVm"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Number of classes, we take for granted\n",
        "CLASSES = 5\n",
        "\n",
        "data = pd.read_pickle('./data/train.pkl')\n",
        "\n",
        "# Sort of one-hot-encode labels ( 2 -> [0, 1, 0, 0, 0])\n",
        "yy = [[1. if i == y else 0. for i in range(CLASSES)] for _, y in data]\n",
        "# Transform x into tensor\n",
        "xx = [torch.Tensor(x) for x, _ in data]\n",
        "# Zip the padded x sequence, and encoded y\n",
        "data = [[x, y] for x, y in zip(xx, yy)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwOGzoP6gKzc"
      },
      "source": [
        "\n",
        "\n",
        "# Getting the test data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "nZ3p4NIEcVhf"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_pickle('./data/test_no_target.pkl')\n",
        "test_data = [torch.Tensor(x) for x in test_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRnoo8IzP1MN"
      },
      "source": [
        "# Data padding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "RuzzAAheP0cs"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def pad_collate(batch, pad_value=0):\n",
        "    xx, yy = zip(*batch)\n",
        "    x_lengths = [len(single_x) for single_x in xx]\n",
        "\n",
        "    xx_pad = pad_sequence(xx, padding_value=pad_value)\n",
        "\n",
        "    return xx_pad, torch.tensor(yy), x_lengths, 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJQ9TIlLbEgk"
      },
      "source": [
        "# Getting the dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "Ixu4qWxjbA47"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "# Sets params\n",
        "batch_size = 32\n",
        "train_to_valid = 0.8\n",
        "\n",
        "# Get the index for splitting data into train and valid sets\n",
        "valid_index = int(train_to_valid * len(data))\n",
        "\n",
        "trainset, validset = torch.utils.data.random_split(data, [valid_index, len(data) - valid_index], generator=torch.Generator().manual_seed(SEED))\n",
        "\n",
        "#Data sampling\n",
        "classes = {}\n",
        "\n",
        "# Proportional to classcounts\n",
        "# for _, y in trainset:\n",
        "#   y = np.argmax(y)\n",
        "#   if y not in classes.keys():\n",
        "#     classes[y] = 1\n",
        "#   else:\n",
        "#     classes[y] += 1\n",
        "# for key in classes.keys():\n",
        "#   classes[key] = 1./classes[key]\n",
        "\n",
        "# Custom\n",
        "classes = {0: 0.3, 1: 0.5, 2: 0.8, 3: 0.9, 4: 0.8}\n",
        "\n",
        "y_classified = [np.argmax(y) for _, y in trainset]\n",
        "example_weights = [classes[e] for e in y_classified]\n",
        "\n",
        "sampler = WeightedRandomSampler(example_weights, len(trainset))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, sampler=sampler, batch_size=batch_size,\n",
        "                                          num_workers=2, collate_fn=pad_collate)\n",
        "\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
        "                                          num_workers=2, collate_fn=pad_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UxAI6rIysw2"
      },
      "source": [
        "Quick note: After testing, proportional to class counts example_weights were performing amazingly well for all classes expect the biggest one - 0, achieving accuracy of about 13%. I've decided to skip mathematical formulas and just eyebal some 'custom' values and it went well enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "ZnzQS9ExYbVo"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_hidden, num_layers, out_size):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_hidden = num_hidden\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
        "        \n",
        "        # Linear layers\n",
        "        self.fc1 = nn.Linear(hidden_size, num_hidden)\n",
        "        self.act = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(num_hidden, out_size)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x dimensions should be [sequence_len, batch_size, output_size]\n",
        "\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        all_outputs = all_outputs[-1] # Take the last prediction\n",
        "        x = self.act(self.fc1(all_outputs))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x, hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "4aEtlKcZYbVo"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "net = LSTM(input_size=1, hidden_size=50, num_hidden=500, num_layers=1, out_size=5).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.003)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-iLuinhHPEz",
        "outputId": "e09e91ac-69b9-4388-bf74-c33b63fe3d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 3.43\n",
            "Epoch: 10, loss: 3.42\n",
            "Epoch: 20, loss: 3.35\n",
            "Epoch: 30, loss: 3.36\n",
            "Epoch: 40, loss: 3.36\n",
            "Epoch: 50, loss: 3.34\n",
            "Epoch: 60, loss: 3.32\n",
            "Epoch: 70, loss: 3.31\n",
            "Epoch: 80, loss: 3.14\n",
            "Epoch: 90, loss: 3.0\n",
            "Epoch: 100, loss: 2.7\n",
            "Epoch: 110, loss: 2.61\n",
            "Epoch: 120, loss: 2.43\n",
            "Epoch: 130, loss: 2.18\n",
            "Epoch: 140, loss: 2.27\n",
            "Epoch: 150, loss: 2.02\n",
            "Epoch: 160, loss: 1.86\n",
            "Epoch: 170, loss: 1.81\n",
            "Epoch: 180, loss: 1.97\n",
            "Epoch: 190, loss: 2.84\n",
            "Epoch: 200, loss: 2.55\n",
            "Epoch: 210, loss: 2.16\n",
            "Epoch: 220, loss: 2.03\n",
            "Epoch: 230, loss: 1.93\n",
            "Epoch: 240, loss: 1.81\n",
            "Epoch: 250, loss: 1.65\n",
            "Epoch: 260, loss: 1.57\n",
            "Epoch: 270, loss: 1.49\n",
            "Epoch: 280, loss: 1.99\n",
            "Epoch: 290, loss: 1.36\n",
            "Epoch: 300, loss: 1.22\n"
          ]
        }
      ],
      "source": [
        "net.train()\n",
        "\n",
        "epochs = 301\n",
        "stateful = False\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for x, targets, x_len, y_len in trainloader:\n",
        "        # Get inputs (x) and change the dimension to fit the designated one\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Initialize hidden and state\n",
        "        hidden, state = net.init_hidden(x.size(1))\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "        # Get predictions ( X -> [batch_size, sequence_length, output_size])\n",
        "        preds, _ = net(x, (hidden, state))\n",
        "        preds = preds.squeeze(1)\n",
        "\n",
        "        # Back-propagate\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}, loss: {running_loss/batch_size:.3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKfTDFyibZp3"
      },
      "source": [
        "# Testing on trainset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMiWfGfwbcwr",
        "outputId": "eb119675-c40a-4ac5-b840-7e0bf56739f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 0: 83.65%\n",
            "Accuracy of 1: 78.70%\n",
            "Accuracy of 2: 21.78%\n",
            "Accuracy of 3: 98.26%\n",
            "Accuracy of 4: 90.00%\n",
            "Accuracy of model: 90.00%\n"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "\n",
        "true_preds = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "all_preds = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "# Training loop\n",
        "for x, targets, _, __ in trainloader:        \n",
        "    x = x.to(device).unsqueeze(2)\n",
        "    targets = targets.to(device)\n",
        "    hidden, state = net.init_hidden(x.size(1))\n",
        "    hidden, state = hidden.to(device), state.to(device)\n",
        "    preds, _ = net(x, (hidden, state))\n",
        "    preds = preds.squeeze(1)\n",
        "    _, preds = torch.max(preds, 1)\n",
        "    _, targets = torch.max(targets, 1)\n",
        "    for pred, target in zip(preds, targets):\n",
        "      pred, target = pred.item(), target.item()\n",
        "      all_preds[target] += 1\n",
        "      if pred == target:\n",
        "        true_preds[target] += 1\n",
        "acc = {}\n",
        "for classname in range(5):\n",
        "  acc = true_preds[classname]/all_preds[classname]\n",
        "  print(f\"Accuracy of {classname}: {100.0*acc:4.2f}%\")\n",
        "\n",
        "correct_total = 0\n",
        "total_total = 0\n",
        "for classsname in range(5):\n",
        "  correct_total += true_preds[classname]\n",
        "  total_total += all_preds[classname]\n",
        "acc = correct_total/total_total\n",
        "print(f\"Accuracy of model: {100.0*acc:4.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS8e-ukE2dDv"
      },
      "source": [
        "## Testing on validset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9gVNEJm2jCW",
        "outputId": "b043244d-971d-4161-ed2d-5fcd92c7b2a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of 0: 70.25%\n",
            "Accuracy of 1: 66.32%\n",
            "Accuracy of 2: 13.79%\n",
            "Accuracy of 3: 74.16%\n",
            "Accuracy of 4: 71.43%\n",
            "Accuracy of model: 71.43%\n"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "\n",
        "true_preds = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "all_preds = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "# Training loop\n",
        "for x, targets, _, __ in validloader:        \n",
        "    x = x.to(device).unsqueeze(2)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    hidden, state = net.init_hidden(x.size(1))\n",
        "    hidden, state = hidden.to(device), state.to(device)\n",
        "    preds, _ = net(x, (hidden, state))\n",
        "    preds = preds.squeeze(1)\n",
        "    _, preds = torch.max(preds, 1)\n",
        "    _, targets = torch.max(targets, 1)\n",
        "    for pred, target in zip(preds, targets):\n",
        "      pred, target = pred.item(), target.item()\n",
        "      all_preds[target] += 1\n",
        "      if pred == target:\n",
        "        true_preds[target] += 1\n",
        "acc = {}\n",
        "for classname in range(5):\n",
        "  acc = true_preds[classname]/all_preds[classname]\n",
        "  print(f\"Accuracy of {classname}: {100.0*acc:4.2f}%\")\n",
        "\n",
        "correct_total = 0\n",
        "total_total = 0\n",
        "for classsname in range(5):\n",
        "  correct_total += true_preds[classname]\n",
        "  total_total += all_preds[classname]\n",
        "acc = correct_total/total_total\n",
        "print(f\"Accuracy of model: {100.0*acc:4.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MvOeCP8gTIT"
      },
      "source": [
        "# Getting the testset predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "CIbhLvNQbCUZ"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for input in test_data:\n",
        "    input = input.to(device).unsqueeze(1).unsqueeze(2)\n",
        "    hidden, state = net.init_hidden(input.size(1))\n",
        "    hidden, state = hidden.to(device), state.to(device)\n",
        "    preds, _ = net(input, (hidden, state))\n",
        "    preds = preds.squeeze()\n",
        "    preds = np.argmax(preds.cpu().detach().numpy())\n",
        "    final_predictions.append(preds)\n",
        "  \n",
        "pd.DataFrame(final_predictions).to_csv(\"output.csv\", index=False, header=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
